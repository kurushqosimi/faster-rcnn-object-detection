import torch
import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.datasets import VOCDetection
import torchvision.transforms as T
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np


# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
transform = T.Compose([
    T.ToTensor(),
])

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Pascal VOC
dataset = VOCDetection(root='./data', year='2012', image_set='train', download=True, transform=transform)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç Faster R-CNN
def collate_fn(batch):
    return tuple(zip(*batch))

# DataLoader
data_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)

# –ì–æ—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å Faster R-CNN —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
model = fasterrcnn_resnet50_fpn(pretrained=True)

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ (20 –∫–ª–∞—Å—Å–æ–≤ Pascal VOC + —Ñ–æ–Ω)
num_classes = 21 

# –ú–µ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–¥ –Ω–∞—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)

# –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
num_epochs = 2  # –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 2 —ç–ø–æ—Ö
model.train()

for epoch in range(num_epochs):
    epoch_loss = 0
    for images, targets in data_loader:
        images = list(img.to(device) for img in images)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ü–µ–ª–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (bbox –∏ labels)
        targets_formatted = []
        for target in targets:
            boxes = []
            labels = []
            obj = target['annotation']['object']
            if not isinstance(obj, list):
                obj = [obj]
            for o in obj:
                bbox = o['bndbox']
                box = [int(bbox['xmin']), int(bbox['ymin']), int(bbox['xmax']), int(bbox['ymax'])]
                boxes.append(box)
                labels.append(int(o['name'] == 'person'))  # –ø—Ä–∏–º–µ—Ä: —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ç–æ–ª—å–∫–æ –ª—é–¥–µ–π (–∫–ª–∞—Å—Å person = 1)

            boxes = torch.as_tensor(boxes, dtype=torch.float32).to(device)
            labels = torch.as_tensor(labels, dtype=torch.int64).to(device)
            
            targets_formatted.append({"boxes": boxes, "labels": labels})
        
        # –®–∞–≥ –æ–±—É—á–µ–Ω–∏—è
        loss_dict = model(images, targets_formatted)
        losses = sum(loss for loss in loss_dict.values())
        
        optimizer.zero_grad()
        losses.backward()
        optimizer.step()
        
        epoch_loss += losses.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")

print("üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

model.eval()
img, _ = dataset[0]
with torch.no_grad():
    prediction = model([img.to(device)])

plt.imshow(img.permute(1,2,0))
ax = plt.gca()

for box, score in zip(prediction[0]['boxes'], prediction[0]['scores']):
    if score > 0.7:  
        xmin, ymin, xmax, ymax = box.cpu().numpy()
        rect = plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, color='red', linewidth=2)
        ax.add_patch(rect)

plt.title('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã Faster R-CNN')
plt.axis('off')
plt.show()

