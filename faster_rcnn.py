import torch
import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.datasets import VOCDetection
import torchvision.transforms as T
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
transform = T.Compose([
    T.ToTensor(),
])

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Pascal VOC
dataset = VOCDetection(root='./data', year='2012', image_set='train', download=True, transform=transform)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç Faster R-CNN
def collate_fn(batch):
    return tuple(zip(*batch))

# DataLoader
data_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)

# –ì–æ—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å Faster R-CNN —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
model = fasterrcnn_resnet50_fpn(pretrained=True)

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ (20 –∫–ª–∞—Å—Å–æ–≤ Pascal VOC + —Ñ–æ–Ω)
num_classes = 21

# –ú–µ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–¥ –Ω–∞—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)

VOC_CLASSES = [
    '__background__', 'aeroplane', 'bicycle', 'bird', 'boat',
    'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person',
    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)

# –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
num_epochs = 2  # –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –ø–æ—Ç–æ–º, —Å–µ–π—á–∞—Å –¥–ª—è —Ç–µ—Å—Ç–∞ 2 —ç–ø–æ—Ö–∏ —Ö–≤–∞—Ç–∏—Ç
model.train()

for epoch in range(num_epochs):
    epoch_loss = 0
    for images, targets in data_loader:
        images = list(img.to(device) for img in images)

        targets_formatted = []
        for target in targets:
            boxes = []
            labels = []
            objs = target['annotation']['object']
            if not isinstance(objs, list):
                objs = [objs]
            for o in objs:
                bbox = o['bndbox']
                box = [
                    int(bbox['xmin']),
                    int(bbox['ymin']),
                    int(bbox['xmax']),
                    int(bbox['ymax'])
                ]
                boxes.append(box)

                # –í–û–¢ –ì–õ–ê–í–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï!
                labels.append(VOC_CLASSES.index(o['name']))

            boxes = torch.as_tensor(boxes, dtype=torch.float32).to(device)
            labels = torch.as_tensor(labels, dtype=torch.int64).to(device)

            targets_formatted.append({"boxes": boxes, "labels": labels})

        # –®–∞–≥ –æ–±—É—á–µ–Ω–∏—è
        loss_dict = model(images, targets_formatted)
        losses = sum(loss for loss in loss_dict.values())

        optimizer.zero_grad()
        losses.backward()
        optimizer.step()

        epoch_loss += losses.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")

print("üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –Ω–∞ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–∞—Ö Pascal VOC!")

model.eval()

CLASSES = [
    '__background__', 'aeroplane', 'bicycle', 'bird', 'boat',
    'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person',
    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

num_tests = 10
detected_objects = []

fig, axs = plt.subplots(2, 5, figsize=(20, 8))
axs = axs.flatten()

for img_idx in range(num_tests):
    img, _ = dataset[img_idx]
    with torch.no_grad():
        prediction = model([img.to(device)])

    axs[img_idx].imshow(img.permute(1, 2, 0))
    axs[img_idx].axis('off')
    axs[img_idx].set_title(f'–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_idx+1}')

    for obj_idx, (box, score, label) in enumerate(zip(prediction[0]['boxes'], prediction[0]['scores'], prediction[0]['labels'])):
        if score > 0.7:
            xmin, ymin, xmax, ymax = box.cpu().numpy()
            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, 
                                 fill=False, color='red', linewidth=2)
            axs[img_idx].add_patch(rect)

            # –ù–æ–º–µ—Ä –æ–±—ä–µ–∫—Ç–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            axs[img_idx].text(xmin, ymin - 10, f'{obj_idx+1}', color='yellow', fontsize=12, weight='bold')

            # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–µ–µ –æ–±—ä–µ–∫—Ç
            class_name = CLASSES[label]
            detected_objects.append({
                'image_number': img_idx+1,
                'object_number': obj_idx+1,
                'class': class_name,
                'score': float(score.cpu().numpy())
            })

# –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ –º–µ—Å—Ç–∞, —á—Ç–æ–±—ã –≤—ã–≥–ª—è–¥–µ–ª–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
plt.tight_layout()
plt.show()

# –¢–µ–ø–µ—Ä—å –≤—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤
fig, ax = plt.subplots(figsize=(10, len(detected_objects)*0.5))
ax.axis('off')
plt.title('–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤', fontsize=14)

# –ì–æ—Ç–æ–≤–∏–º –∫—Ä–∞—Å–∏–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≤—ã–≤–æ–¥–∞
text_info = '\n'.join([
    f"–ò–∑–æ–±—Ä. {obj['image_number']}, –û–±—ä–µ–∫—Ç {obj['object_number']}: {obj['class']} ({obj['score']:.2f})"
    for obj in detected_objects
])

plt.text(0, 1, text_info, fontsize=12, verticalalignment='top')
plt.show()


# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –≤ —Ñ–∞–π–ª fasterrcnn_model.pth
torch.save(model.state_dict(), 'fasterrcnn_model.pth')







